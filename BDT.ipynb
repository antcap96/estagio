{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "import pandas\n",
    "\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import sys\n",
    "sys.path.append('./modules/')\n",
    "from Processors import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403 events for Higgs with 260 GeV\n",
      "394 events for Higgs with 270 GeV\n",
      "390 events for Higgs with 280 GeV\n",
      "372 events for Higgs with 300 GeV\n",
      "479 events for Higgs with 320 GeV\n",
      "655 events for Higgs with 400 GeV\n",
      "1619 events for Higgs with 500 GeV\n",
      "1858 events for Higgs with 550 GeV\n",
      "2008 events for Higgs with 600 GeV\n",
      "2239 events for Higgs with 700 GeV\n",
      "166157 TT_Tune events\n",
      "1896 WJetsToLNu_Tune events\n",
      "\n",
      "10417 events of Higgs\n",
      "168053 background events\n"
     ]
    }
   ],
   "source": [
    "loc = './Data/'\n",
    "\n",
    "energies = [260, 270, 280, 300, 320, 400, 500, 550, 600, 700]\n",
    "\n",
    "signalData = []\n",
    "backgroundData = []\n",
    "\n",
    "for energy in energies:\n",
    "    signalData.append(pandas.read_csv(loc + \"GluGluToRadionToHHTo2B2Tau_M-\" + \n",
    "                                      str(energy) + \"_narrow_13TeV-madgraph.csv\"))\n",
    "\n",
    "# same as 2 but only the first half of the events\n",
    "#backgroundData.append(pandas.read_csv(loc + \"TT_TuneCUETP8M1_13TeV-powheg-pythia8_1.csv\"))\n",
    "backgroundData.append(pandas.read_csv(loc + \"TT_TuneCUETP8M1_13TeV-powheg-pythia8_2.csv\"))\n",
    "backgroundData.append(pandas.read_csv(loc + \"WJetsToLNu_TuneCUETP8M1_13TeV-amcatnloFXFX-pythia8.csv\"))\n",
    "\n",
    "\n",
    "# drop columns without header\n",
    "for signal_data in signalData:\n",
    "    signal_data.drop([x for x in signal_data.columns if 'Unnamed' in x], axis=1, inplace=True)\n",
    "\n",
    "for background_data in backgroundData:\n",
    "    background_data.drop([x for x in background_data.columns if 'Unnamed' in x], axis=1, inplace=True)\n",
    "\n",
    "allSignalData = signalData[0]\n",
    "for signal_data in signalData[1:]:\n",
    "    allSignalData = allSignalData.append(signal_data, ignore_index=True)\n",
    "\n",
    "allBackgroundData = backgroundData[0]\n",
    "for background_data in backgroundData[1:]:\n",
    "    allBackgroundData = allBackgroundData.append(background_data, ignore_index=True)\n",
    "\n",
    "for i in range(len(energies)):\n",
    "    print(\"{} events for Higgs with {} GeV\".format(len(signalData[i]), energies[i]))\n",
    "print(\"{} TT_Tune events\".format(len(backgroundData[0])))\n",
    "print(\"{} WJetsToLNu_Tune events\".format(len(backgroundData[1])), end='\\n\\n')\n",
    "print(\"{} events of Higgs\".format(len(allSignalData)))\n",
    "print(\"{} background events\".format(len(allBackgroundData)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column for classification\n",
    "#allSignalData['gen_classification'] = np.ones(len(allSignalData))\n",
    "#allBackgroundData['gen_classification'] = np.zeros(len(allBackgroundData))\n",
    "\n",
    "allData = allSignalData.append(allBackgroundData, ignore_index=True)\n",
    "allLabels = np.append(np.ones(len(allSignalData)),np.zeros(len(allBackgroundData)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "particles = ['t_0', 't_1', 'b_0', 'b_1', 'h_tt', 'h_bb', 'diH']\n",
    "\n",
    "for p in particles:\n",
    "    moveToCartesian(allData, p) #Move pT, eta, and phi to p_x, p_y, and p_z\n",
    "    addEnergy(allData, p) #Calculate energy and absolute momentum\n",
    "    \n",
    "moveToCartesian(allData, 'mPT', False)  #Move Missing pT and phi to p_x and p_y\n",
    "addAbsMom(allData, 'mPT', False) #Calculate absolute missing transverse momentum\n",
    "addMT(allData, allData['t_1_pT'], allData['t_1_phi'], 't_1') #Calculate transverse mass of tau_mu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## select train variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "genFeatures = [var for var in allData.columns if str.startswith(var, \"gen\")] #Generator features; not for training\n",
    "trainFeatures = [var for var in allData.columns if var not in genFeatures] #Reconstructed features; ok for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pTEtaPhi = [var for var in trainFeatures for x in ['phi', 't_1_mass'] if x in var] # 'pT', 'eta', \n",
    "trainFeatures = [var for var in trainFeatures if var not in pTEtaPhi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsFeatures = [var for var in trainFeatures for p in particles + ['mPT'] if p in var]\n",
    "shapes = [var for var in trainFeatures for x in ['aplan', 'dShape', 'spher', 'upsilon'] if x in var]\n",
    "shapeFeatures = [var for var in trainFeatures if var in shapes]\n",
    "eventKinematicFeatures = ['centrality', 'eVis', 'hT', 'sT']\n",
    "jetFeatures = [var for var in trainFeatures if 'Jet' in var and 'Jets' not in var]\n",
    "multiplicityFeatures = ['nBJets', 'nJets', 'nPhotons', 'nTauJets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 65 features ['t_0_pT', 't_0_eta', 't_0_mass', 't_1_pT', 't_1_eta', 'b_0_pT', 'b_0_eta', 'b_0_mass', 'b_0_csv', 'b_1_pT', 'b_1_eta', 'b_1_mass', 'b_1_csv', 'mPT_pT', 'h_tt_pT', 'h_tt_eta', 'h_tt_mass', 'h_tt_svFit_mass', 'h_bb_pT', 'h_bb_eta', 'h_bb_mass', 'diH_pT', 'diH_eta', 'diH_mass', 'diH_kinFit_mass', 'diH_kinFit_prob', 't_0_px', 't_0_py', 't_0_pz', 't_0_|p|', 't_0_E', 't_1_px', 't_1_py', 't_1_pz', 't_1_|p|', 't_1_E', 'b_0_px', 'b_0_py', 'b_0_pz', 'b_0_|p|', 'b_0_E', 'b_1_px', 'b_1_py', 'b_1_pz', 'b_1_|p|', 'b_1_E', 'h_tt_px', 'h_tt_py', 'h_tt_pz', 'h_tt_|p|', 'h_tt_E', 'h_bb_px', 'h_bb_py', 'h_bb_pz', 'h_bb_|p|', 'h_bb_E', 'diH_px', 'diH_py', 'diH_pz', 'diH_|p|', 'diH_E', 'mPT_px', 'mPT_py', 'mPT_|p|', 't_1_mT']\n"
     ]
    }
   ],
   "source": [
    "classTrainFeatures = fsFeatures\n",
    "print(\"Training on {} features {}\". format(len(classTrainFeatures),[var for var in classTrainFeatures]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(allData[classTrainFeatures], allLabels, test_size=0.2, random_state=2345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scale = len(allBackgroundData)/len(allSignalData)\n",
    "\n",
    "weights_train = np.ones(len(y_train))\n",
    "weights_test = np.ones(len(y_test))\n",
    "\n",
    "weights_train[y_train == 1] = scale\n",
    "weights_test[y_test == 1] = scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
       "       n_estimators=300, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=1337, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=16.132571757703754, seed=None,\n",
       "       silent=False, subsample=1)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model no training data\n",
    "model = xgb.XGBClassifier(random_state=1337, silent=False, scale_pos_weight=scale, objective='binary:logistic',n_estimators=300 , eval_metric='auc')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy           : 93.2593713229114%\n",
      "Accuracy signal    : 91.37844611528823%\n",
      "Accuracy nackground: 93.37072316685955%\n"
     ]
    }
   ],
   "source": [
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy           : {:10}%\".format(accuracy * 100.0))\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions, sample_weight=y_test)\n",
    "print(\"Accuracy signal    : {:10}%\".format(accuracy * 100.0))\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions, sample_weight=np.logical_not(y_test))\n",
    "print(\"Accuracy nackground: {:10}%\".format(accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.940762940051\n",
      "0.923974837206\n"
     ]
    }
   ],
   "source": [
    "print(model.score(X_train, y_train, sample_weight=weights_train))\n",
    "print(model.score(X_test, y_test, sample_weight=weights_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method ClassifierMixin.score of XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
       "       n_estimators=300, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=1337, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=16.132571757703754, seed=None,\n",
       "       silent=False, subsample=1)>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = model.predict(X_test)\n",
    "((test != 0.0) & (test != 1.0)).any()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
